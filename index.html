<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>

  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="L/G's Blog" type="application/atom+xml">






<meta name="description" content="AI/机器学习/数据挖掘/python">
<meta property="og:type" content="website">
<meta property="og:title" content="L&#x2F;G&#39;s Blog">
<meta property="og:url" content="https://17091557073.github.io/index.html">
<meta property="og:site_name" content="L&#x2F;G&#39;s Blog">
<meta property="og:description" content="AI/机器学习/数据挖掘/python">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="L&#x2F;G&#39;s Blog">
<meta name="twitter:description" content="AI/机器学习/数据挖掘/python">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://17091557073.github.io/">





  <title>L/G's Blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">L/G's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://17091557073.github.io/2025/01/09/神经网络代码实现/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gavin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/psb.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="L/G's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2025/01/09/神经网络代码实现/" itemprop="url">简单神经网络实现</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2025-01-09T17:42:00+08:00">
                2025-01-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/神经网络/" itemprop="url" rel="index">
                    <span itemprop="name">神经网络</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong><em>损失函数</em></strong></p>
<p>为什么不直接使用识别精度，而要引入损失函数。因为识别精度对微小的参数变化没有很好的反应（是不连续、很突然的），出于相同的原因，激活函数也不能使用阶跃函数，因为它的导数在绝大多数地方都为零，神经网络的学习将无法进行。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy_error</span><span class="params">(y, t)</span>:</span></span><br><span class="line">    <span class="comment"># 求单个数据的交叉熵误差时，需要改变数据形状</span></span><br><span class="line">    <span class="keyword">if</span> y.ndim == <span class="number">1</span>:</span><br><span class="line">        t = t.reshape(<span class="number">1</span>, t.size)</span><br><span class="line">        y = y.reshape(<span class="number">1</span>, y.size) </span><br><span class="line">    <span class="comment"># 监督数据是one-hot-vector的情况下，转换为正确解标签的索引</span></span><br><span class="line">    <span class="keyword">if</span> t.size == y.size:</span><br><span class="line">        t = t.argmax(axis=<span class="number">1</span>)        </span><br><span class="line">    batch_size = y.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> -np.sum(np.log(y[np.arange(batch_size), t] + <span class="number">1e-7</span>)) / batch_size</span><br></pre></td></tr></table></figure></p>
<p><strong><em>梯度法</em></strong></p>
<p>神经网络在学习时使用梯度法找到最优参数（即权重和偏置，也就是损失函数取最小值时的参数），梯度表示各点处函数值减小最多的方向。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">numerical_gradient</span><span class="params">(f, x)</span>:</span></span><br><span class="line">    h = <span class="number">1e-4</span> <span class="comment"># 0.0001，超参数：学习率，步长</span></span><br><span class="line">    grad = np.zeros_like(x)</span><br><span class="line">    it = np.nditer(x, flags=[<span class="string">'multi_index'</span>], op_flags=[<span class="string">'readwrite'</span>])</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> it.finished:</span><br><span class="line">        idx = it.multi_index</span><br><span class="line">        tmp_val = x[idx]</span><br><span class="line">        x[idx] = float(tmp_val) + h</span><br><span class="line">        fxh1 = f(x) <span class="comment"># f(x+h)</span></span><br><span class="line">        x[idx] = tmp_val - h </span><br><span class="line">        fxh2 = f(x) <span class="comment"># f(x-h)</span></span><br><span class="line">        grad[idx] = (fxh1 - fxh2) / (<span class="number">2</span>*h)＃使用中心差分来减小数值微分的误差        </span><br><span class="line">        x[idx] = tmp_val <span class="comment"># 还原值</span></span><br><span class="line">        it.iternext()   </span><br><span class="line">    <span class="keyword">return</span> grad</span><br></pre></td></tr></table></figure></p>
<p><strong><em>学习算法的实现</em></strong></p>
<p>以2层神经网络（隐藏层为1层）为对象，使用MNIST数据集，实现简单的手写数字识别。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> common.functions <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> common.gradient <span class="keyword">import</span> numerical_gradient</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayerNet</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size, weight_init_std=<span class="number">0.01</span>)</span>:</span></span><br><span class="line">        <span class="comment"># 初始化权重</span></span><br><span class="line">        self.params = &#123;&#125;</span><br><span class="line">        self.params[<span class="string">'W1'</span>] = weight_init_std * np.random.randn(input_size, hidden_size)</span><br><span class="line">        self.params[<span class="string">'b1'</span>] = np.zeros(hidden_size)</span><br><span class="line">        self.params[<span class="string">'W2'</span>] = weight_init_std * np.random.randn(hidden_size, output_size)</span><br><span class="line">        self.params[<span class="string">'b2'</span>] = np.zeros(output_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        W1, W2 = self.params[<span class="string">'W1'</span>], self.params[<span class="string">'W2'</span>]</span><br><span class="line">        b1, b2 = self.params[<span class="string">'b1'</span>], self.params[<span class="string">'b2'</span>]</span><br><span class="line">    </span><br><span class="line">        a1 = np.dot(x, W1) + b1</span><br><span class="line">        z1 = sigmoid(a1)</span><br><span class="line">        a2 = np.dot(z1, W2) + b2</span><br><span class="line">        y = softmax(a2)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># x:输入数据, t:监督数据</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(self, x, t)</span>:</span></span><br><span class="line">        y = self.predict(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> cross_entropy_error(y, t)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accuracy</span><span class="params">(self, x, t)</span>:</span></span><br><span class="line">        y = self.predict(x)</span><br><span class="line">        y = np.argmax(y, axis=<span class="number">1</span>)</span><br><span class="line">        t = np.argmax(t, axis=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        accuracy = np.sum(y == t) / float(x.shape[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> accuracy</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># x:输入数据, t:监督数据</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numerical_gradient</span><span class="params">(self, x, t)</span>:</span></span><br><span class="line">        loss_W = <span class="keyword">lambda</span> W: self.loss(x, t)</span><br><span class="line">        </span><br><span class="line">        grads = &#123;&#125;</span><br><span class="line">        grads[<span class="string">'W1'</span>] = numerical_gradient(loss_W, self.params[<span class="string">'W1'</span>])</span><br><span class="line">        grads[<span class="string">'b1'</span>] = numerical_gradient(loss_W, self.params[<span class="string">'b1'</span>])</span><br><span class="line">        grads[<span class="string">'W2'</span>] = numerical_gradient(loss_W, self.params[<span class="string">'W2'</span>])</span><br><span class="line">        grads[<span class="string">'b2'</span>] = numerical_gradient(loss_W, self.params[<span class="string">'b2'</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> grads</span><br></pre></td></tr></table></figure></p>
<p><strong><em>效果评估</em></strong></p>
<p>用随机选择的小批量数据（mini-batch）作为全体训练数据的近似值。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys, os</span><br><span class="line">sys.path.append(os.pardir)  <span class="comment"># 为了导入父目录的文件而进行的设定</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> dataset.mnist <span class="keyword">import</span> load_mnist</span><br><span class="line"><span class="keyword">from</span> two_layer_net <span class="keyword">import</span> TwoLayerNet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入数据</span></span><br><span class="line">(x_train, t_train), (x_test, t_test) = load_mnist(normalize=<span class="literal">True</span>, one_hot_label=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">network = TwoLayerNet(input_size=<span class="number">784</span>, hidden_size=<span class="number">50</span>, output_size=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">iters_num = <span class="number">10000</span>  <span class="comment"># 适当设定循环的次数</span></span><br><span class="line">train_size = x_train.shape[<span class="number">0</span>]</span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">train_loss_list = []</span><br><span class="line">train_acc_list = []</span><br><span class="line">test_acc_list = []</span><br><span class="line"><span class="comment">#平均每个epoch的重复次数</span></span><br><span class="line">iter_per_epoch = max(train_size / batch_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(iters_num):</span><br><span class="line">    batch_mask = np.random.choice(train_size, batch_size)</span><br><span class="line">    x_batch = x_train[batch_mask]</span><br><span class="line">    t_batch = t_train[batch_mask]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算梯度</span></span><br><span class="line">    grad = network.numerical_gradient(x_batch, t_batch)</span><br><span class="line">    <span class="comment">#grad = network.gradient(x_batch, t_batch)#进阶高速版</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新参数</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> (<span class="string">'W1'</span>, <span class="string">'b1'</span>, <span class="string">'W2'</span>, <span class="string">'b2'</span>):</span><br><span class="line">        network.params[key] -= learning_rate * grad[key]</span><br><span class="line">    </span><br><span class="line">    loss = network.loss(x_batch, t_batch)</span><br><span class="line">    train_loss_list.append(loss)</span><br><span class="line">    <span class="comment"># 计算每个epoch的识别精度，没有必要频繁记录，大致把握识别精度的推移即可</span></span><br><span class="line">    <span class="keyword">if</span> i % iter_per_epoch == <span class="number">0</span>:</span><br><span class="line">        train_acc = network.accuracy(x_train, t_train)</span><br><span class="line">        test_acc = network.accuracy(x_test, t_test)</span><br><span class="line">        train_acc_list.append(train_acc)</span><br><span class="line">        test_acc_list.append(test_acc)</span><br><span class="line">        print(<span class="string">"train acc, test acc | "</span> + str(train_acc) + <span class="string">", "</span> + str(test_acc))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制图形</span></span><br><span class="line">markers = &#123;<span class="string">'train'</span>: <span class="string">'o'</span>, <span class="string">'test'</span>: <span class="string">'s'</span>&#125;</span><br><span class="line">x = np.arange(len(train_acc_list))</span><br><span class="line">plt.plot(x, train_acc_list, label=<span class="string">'train acc'</span>)</span><br><span class="line">plt.plot(x, test_acc_list, label=<span class="string">'test acc'</span>, linestyle=<span class="string">'--'</span>)</span><br><span class="line">plt.xlabel(<span class="string">"epochs"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"accuracy"</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">1.0</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p><img src="/2025/01/09/神经网络代码实现/感知机/pasted-1.png" alt="upload successful"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://17091557073.github.io/2024/12/25/财富自由之路/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gavin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/psb.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="L/G's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2024/12/25/财富自由之路/" itemprop="url">财富自由之路</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-12-25T10:23:00+08:00">
                2024-12-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Daily-life/" itemprop="url" rel="index">
                    <span itemprop="name">Daily life</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>财富只是工具，自由才是最终的目的，自由的本质是时间的自主权。<br><strong><em>财富自由</em></strong>是指不需要为了满足生活必需而出售自己的时间了。</p>
<p>专注<strong><em>成长</em></strong>而不是专注成功，财富自由不是终点，只是通往过程中的一个里程碑。<br>每一次选择从积累能力的角度出发，要考虑自己还需要什么能力。</p>
<p>重视<strong><em>价值</em></strong>忽略估值，长期来看，估值是虚幻的，虽有波动，却实际锚定在价值上的，切勿自欺欺人。</p>
<p><strong><em>耐心</em></strong>有复利效应，不能做自己喜欢的事情是人生常态，困难的阶段不过是必经之路。耐心是一切成长的刚需，几乎所有的半途而废，最终都可以归结到这一点：短期期望过高。</p>
<p>不要凑热闹、随大流、瞎操心，把最宝贵的<strong><em>注意力</em></strong>，放在你的成长、真爱和对社会有贡献的事情上。</p>
<p>百分百的<strong><em>安全</em></strong>带来的是百分百的束缚，几乎所有的进步都是放弃了部分安全感获得的。</p>
<p><strong><em>元认知能力</em></strong>：我正在想的是什么；我这么想对不对；我应该怎么想才对。</p>
<p>不能改变的东西尝试接受它；可以改变的东西努力解决它；<strong><em>抱怨</em></strong>是无奈和无能的表现。</p>
<p><strong><em>有勇</em></strong>：愿意为自己的行为负责，不论做什么事，都不推卸责任，承担一切后果；<strong><em>有谋</em></strong>：不会意气用事，做事讲逻辑，尊重事物发展的规律，不违背大势行动。</p>
<p>人所拥有的任何东西都可以被剥夺，唯独<strong><em>人性最后的自由</em></strong>（也就是在任何境遇中选择自己态度和生活方式的自由）不能被剥夺。</p>
<p><strong><em>认清差异</em></strong>是我们消除差异的第一步。不能一味地否定事实，要敢于正视现实差距，看到别人的财富，要想到这只是内在差距的外在体现而已。试着去学习对方的优点，从内到外不断磨平差距。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://17091557073.github.io/2024/12/24/神经网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gavin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/psb.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="L/G's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2024/12/24/神经网络/" itemprop="url">激活函数</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-12-24T21:16:00+08:00">
                2024-12-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/神经网络/" itemprop="url" rel="index">
                    <span itemprop="name">神经网络</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="线性"><a href="#线性" class="headerlink" title="线性"></a>线性</h4><p>h(x)=cx</p>
<p>神经网络的激活函数一般会使用非线性函数，若使用线性函数则加深层数就没有意义了，如h(h(h(x)))=c^3*x</p>
<h4 id="非线性"><a href="#非线性" class="headerlink" title="非线性"></a>非线性</h4><p>最后输出层所用的激活函数，要根据求解问题的性质决定。一般地，回归问题用恒等函数；二元分类问题用sigmoid函数；多元分类问题用softmax函数。</p>
<p>1、阶跃函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step_function</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.array(x&gt;<span class="number">0</span>,dtype=np.int)</span><br></pre></td></tr></table></figure></p>
<p>2、sigmoid函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br></pre></td></tr></table></figure></p>
<p>3、ReLU函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.maximum(<span class="number">0</span>, x)</span><br></pre></td></tr></table></figure></p>
<p>4、softmax函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> x.ndim == <span class="number">2</span>:</span><br><span class="line">        x = x.T</span><br><span class="line">        x = x - np.max(x, axis=<span class="number">0</span>)</span><br><span class="line">        y = np.exp(x) / np.sum(np.exp(x), axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> y.T </span><br><span class="line">    x = x - np.max(x) <span class="comment"># 溢出对策</span></span><br><span class="line">    <span class="keyword">return</span> np.exp(x) / np.sum(np.exp(x))</span><br></pre></td></tr></table></figure></p>
<h4 id="案例：手写数字识别"><a href="#案例：手写数字识别" class="headerlink" title="案例：手写数字识别"></a>案例：手写数字识别</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> sys,os</span><br><span class="line">sys.path.append(os.pardir)</span><br><span class="line"><span class="keyword">from</span> dataset.mnist <span class="keyword">import</span> load_mnist</span><br><span class="line">(x_train,t_train),(x_test,t_test)=load_mnist(flatten=<span class="literal">True</span>,normalize=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> (x_train,t_train,x_test,t_test):</span><br><span class="line">    print(i.shape)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img_show</span><span class="params">(img)</span>:</span></span><br><span class="line">    pil_img=Image.fromarray(np.uint8(img))</span><br><span class="line">    pil_img.show()</span><br><span class="line">img=x_train[<span class="number">0</span>].reshape(<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line">label=t_train[<span class="number">0</span>]</span><br><span class="line">img_show(img)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">()</span>:</span></span><br><span class="line">    (x_train,t_train),(x_test,t_test)=load_mnist(normalize=<span class="literal">True</span>,flatten=<span class="literal">True</span>,one_hot_label=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> x_test,t_test</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_network</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">'''假设之前学习已经完成，将学习到的参数保存下来，现在直接加载'''</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"sample_weight.pkl"</span>,<span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        network=pickle.load(f)</span><br><span class="line">        <span class="keyword">return</span> network</span><br><span class="line"><span class="keyword">from</span> common.functions <span class="keyword">import</span> sigmoid, softmax</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(network,x)</span>:</span></span><br><span class="line">    W1,W2,W3=network[<span class="string">'W1'</span>],network[<span class="string">'W2'</span>],network[<span class="string">'W3'</span>]    </span><br><span class="line">    b1,b2,b3=network[<span class="string">'b1'</span>],network[<span class="string">'b2'</span>],network[<span class="string">'b3'</span>]</span><br><span class="line">    a1=np.dot(x,W1)+b1</span><br><span class="line">    z1=sigmoid(a1)</span><br><span class="line">    a2=np.dot(z1,W2)+b2</span><br><span class="line">    z2=sigmoid(a2)</span><br><span class="line">    a3 = np.dot(z2, W3) + b3</span><br><span class="line">    y = softmax(a3)</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line">x,t=get_data()</span><br><span class="line">network=init_network()</span><br><span class="line">accuracy_cnt = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(x)):</span><br><span class="line">    y = predict(network, x[i])</span><br><span class="line">    p= np.argmax(y) <span class="comment"># 获取概率最高的元素的索引</span></span><br><span class="line">    <span class="keyword">if</span> p == t[i]:</span><br><span class="line">        accuracy_cnt += <span class="number">1</span></span><br><span class="line">print(<span class="string">"Accuracy:"</span> + str(float(accuracy_cnt) / len(x)))</span><br><span class="line"><span class="comment">#优化流程，修改为批处理方式，大幅提高计算速度</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">accuracy_cnt = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(x), batch_size):</span><br><span class="line">    x_batch = x[i:i+batch_size]</span><br><span class="line">    y_batch = predict(network, x_batch)</span><br><span class="line">    p = np.argmax(y_batch, axis=<span class="number">1</span>)</span><br><span class="line">    accuracy_cnt += np.sum(p == t[i:i+batch_size])</span><br><span class="line">print(<span class="string">"Accuracy:"</span> + str(float(accuracy_cnt) / len(x)))</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://17091557073.github.io/2024/12/23/感知机/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gavin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/psb.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="L/G's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2024/12/23/感知机/" itemprop="url">感知机</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-12-23T19:56:00+08:00">
                2024-12-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/神经网络/" itemprop="url" rel="index">
                    <span itemprop="name">神经网络</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h6 id="单层感知机"><a href="#单层感知机" class="headerlink" title="单层感知机"></a>单层感知机</h6><p>又称朴素感知机，只能表示线性空间，以下示例参数（w1,w2,b）由人工确定。</p>
<ul>
<li><p>与门<br><img src="/2024/12/23/感知机/pasted-1.png" alt="upload successful"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">AND</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">    <span class="comment">#输入信号</span></span><br><span class="line">    x=np.array([x1,x2])</span><br><span class="line">    <span class="comment">#权重，控制输入信号的重要性</span></span><br><span class="line">    w=np.array([<span class="number">0.5</span>,<span class="number">0.5</span>])</span><br><span class="line">    <span class="comment">#偏置，调整神经元被激活的容易程度</span></span><br><span class="line">    b=<span class="number">-0.7</span></span><br><span class="line">    <span class="comment">#输出</span></span><br><span class="line">    tmp=np.sum(w*x)+b</span><br><span class="line">    <span class="keyword">if</span> tmp&lt;=<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>或门<br><img src="/2024/12/23/感知机/pasted-3.png" alt="upload successful"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">OR</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">    x=np.array([x1,x2])</span><br><span class="line">    <span class="comment">#仅权重和偏置与AND不同</span></span><br><span class="line">    w=np.array([<span class="number">0.5</span>,<span class="number">0.5</span>])</span><br><span class="line">    b=<span class="number">0.2</span></span><br><span class="line">    tmp=np.sum(w*x)+b</span><br><span class="line">    <span class="keyword">if</span> tmp&lt;=<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>与非门<br><img src="/2024/12/23/感知机/pasted-2.png" alt="upload successful"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">NAND</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">    x=np.array([x1,x2])</span><br><span class="line">    <span class="comment">#仅权重和偏置与AND不同</span></span><br><span class="line">    w=np.array([<span class="number">-0.5</span>,<span class="number">-0.5</span>])</span><br><span class="line">    b=<span class="number">0.7</span></span><br><span class="line">    tmp=np.sum(w*x)+b</span><br><span class="line">    <span class="keyword">if</span> tmp&lt;=<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h6 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h6><p>可以表示非线性空间</p>
<p><img src="/2024/12/23/感知机/pasted-5.png" alt="upload successful"></p>
<ul>
<li>异或门<br><img src="/2024/12/23/感知机/pasted-4.png" alt="upload successful"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">XOR</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">    s1=NAND(x1,x2)</span><br><span class="line">    s2=OR(x1,x2)</span><br><span class="line">    y=AND(s1,s2)</span><br><span class="line">    <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://17091557073.github.io/2021/10/06/等额本金vs等额本息/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gavin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/psb.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="L/G's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/10/06/等额本金vs等额本息/" itemprop="url">等额本金 or 本息区别</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-10-06T10:22:00+08:00">
                2021-10-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/金融/" itemprop="url" rel="index">
                    <span itemprop="name">金融</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h6 id="月还款额及利息公式推导"><a href="#月还款额及利息公式推导" class="headerlink" title="月还款额及利息公式推导"></a>月还款额及利息公式推导</h6><p><img src="/2021/10/06/等额本金vs等额本息/公式推导.jpg" alt="公式推导"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://17091557073.github.io/2019/06/08/支持向量机/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gavin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/psb.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="L/G's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/08/支持向量机/" itemprop="url">支持向量机</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-06-08T16:43:00+08:00">
                2019-06-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习实战/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习实战</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h6 id="基本线性SVM推导"><a href="#基本线性SVM推导" class="headerlink" title="基本线性SVM推导"></a>基本线性SVM推导</h6><p><a href="https://mp.weixin.qq.com/s/Ahvp0IAdgK9OVHFXigBk_Q" target="_blank" rel="noopener"><em>参考文献_线性SVM</em></a><br><a href="https://mp.weixin.qq.com/s/Q5bFR3vDDXPhtzXlVAE3Rg" target="_blank" rel="noopener"><em>参考文献_对偶SVM</em></a><br><img src="/2019/06/08/支持向量机/基本线性SVM推导.jpg" alt="基本线性SVM推导"></p>
<h6 id="SMO优化算法推导"><a href="#SMO优化算法推导" class="headerlink" title="SMO优化算法推导"></a>SMO优化算法推导</h6><p>在KKT约束条件下,最小化目标函数。序列最小优化（SMO）：<br><img src="/2019/06/08/支持向量机/SMO推导.jpg" alt="SMO推导"></p>
<h6 id="超参数详解"><a href="#超参数详解" class="headerlink" title="超参数详解"></a>超参数详解</h6><p><img src="/2019/06/08/支持向量机/超参数详解.png" alt="超参数详解"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://17091557073.github.io/2019/05/26/Logistic回归/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gavin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/psb.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="L/G's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/26/Logistic回归/" itemprop="url">Logistic回归</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-26T23:00:00+08:00">
                2019-05-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习实战/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习实战</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h6 id="主要思想："><a href="#主要思想：" class="headerlink" title="主要思想："></a><strong>主要思想：</strong></h6><p>根据现有数据，对分类边界线建立回归方程（用一条直线对数据点进行拟合的过程称作回归），使用最优化算法，找到最佳拟合参数集。 </p>
<h6 id="Sigmoid函数："><a href="#Sigmoid函数：" class="headerlink" title="Sigmoid函数："></a><strong>Sigmoid函数：</strong></h6><p>为了实现Logistic回归分类器，我们在每个特征上都乘以一个回归系数，然后把所有结果值相加，将这个总和代入Sigmoid阶跃函数中，进而得到一个[0,1]之间的数值，大于0.5的数据归入1类，小于0.5归入0类，所以Logistic回归也被看成一个概率估计。</p>
<h6 id="极大似然估计-amp-交叉熵损失函数："><a href="#极大似然估计-amp-交叉熵损失函数：" class="headerlink" title="极大似然估计&amp;交叉熵损失函数："></a><strong>极大似然估计&amp;交叉熵损失函数：</strong></h6><p><img src="/2019/05/26/Logistic回归/交叉熵损失函数.jpg" alt="交叉熵损失函数推导"></p>
<h6 id="最优化算法："><a href="#最优化算法：" class="headerlink" title="最优化算法："></a><strong>最优化算法：</strong></h6><ul>
<li>梯度下降求损失函数最小值<br>  <img src="/2019/05/26/Logistic回归/交叉熵损失函数求偏导.png" alt="交叉熵损失函数求偏导"></li>
<li>梯度上升算法<br>要找到某个函数的最大值，最好的方法就是沿着该函数的梯度方向（即函数值增长最快的方向）探寻，设置步长，每移动一步到达下个点后会重新计算梯度方向，如此循环迭代，直至迭代次数达到某个指定值或算法达到某个可以允许的误差范围。</li>
<li>随机梯度上升算法<br>  对梯度上升算法的改进，每次仅用一个样本点来更新回归系数，降低算法复杂度。可以在新样本到来时，对分类器进行增量式参数更新，不需要重新读取整个数据集进行批处理运算，是一种<strong>在线学习</strong>算法。</li>
</ul>
<hr>
<h6 id="python代码实现"><a href="#python代码实现" class="headerlink" title="python代码实现"></a>python代码实现</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Sun Jun  2 17:08:04 2019</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: LiGuan</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@desc: 逻辑回归</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    加载数据集</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    dataMat,labelMat=[],[]</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">r'C:\Users\ligua\Videos\我的资源\机器学习实战\machinelearninginaction\Ch05\testSet.txt'</span>) <span class="keyword">as</span> fr:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">            lineArr=line.strip().split()</span><br><span class="line">            <span class="comment">#设置初始截距项</span></span><br><span class="line">            dataMat.append([<span class="number">1</span>,float(lineArr[<span class="number">0</span>]),float(lineArr[<span class="number">1</span>])])</span><br><span class="line">            labelMat.append(int(lineArr[<span class="number">2</span>]))</span><br><span class="line">    <span class="keyword">return</span> dataMat,labelMat</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(inX)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    阶跃函数</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-inX))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span><span class="params">(dataMatIn,classLabels)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    最优化算法：梯度上升</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    dataMatrix=np.mat(dataMatIn)</span><br><span class="line">    labelMat=np.mat(classLabels).transpose()</span><br><span class="line">    m,n=np.shape(dataMatrix)</span><br><span class="line">    <span class="comment">#定义步长、最大迭代次数和初始权重参数</span></span><br><span class="line">    alpha=<span class="number">0.001</span></span><br><span class="line">    maxCycles=<span class="number">500</span></span><br><span class="line">    weights=np.ones((n,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(maxCycles):</span><br><span class="line">        h=sigmoid(dataMatrix*weights)</span><br><span class="line">        error=labelMat-h</span><br><span class="line">        weights=weights+alpha*dataMatrix.transpose()*error</span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent0</span><span class="params">(dataMatrix,classLabels)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    随机梯度上升算法</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    m,n=np.shape(dataMatrix)</span><br><span class="line">    alpha=<span class="number">0.01</span></span><br><span class="line">    weights=np.ones(n)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        h=sigmoid(sum(dataMatrix[i]*weights))</span><br><span class="line">        error=classLabels[i]-h</span><br><span class="line">        weights=weights+alpha*error*dataMatrix[i]</span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent1</span><span class="params">(dataMatrix,classLabels,numIter=<span class="number">150</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    改进后的随机梯度算法</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    m,n=np.shape(dataMatrix)</span><br><span class="line">    weights=np.ones(n)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(numIter):</span><br><span class="line">        dataIndex=list(range(m))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            alpha=<span class="number">4</span>/(<span class="number">1.0</span>+j+i)+<span class="number">0.01</span><span class="comment">#在每次迭代的时候调整步长,加一个常数项，永远不会减小到0，保证多次迭代后新数据仍然具有一定的影响</span></span><br><span class="line">            randIndex=int(random.uniform(<span class="number">0</span>,len(dataIndex)))<span class="comment">#随机选取样本更新系数，减少周期性波动</span></span><br><span class="line">            h=sigmoid(sum(dataMatrix[randIndex]*weights))</span><br><span class="line">            error=classLabels[randIndex]-h</span><br><span class="line">            weights=weights+alpha*error*dataMatrix[randIndex]</span><br><span class="line">            <span class="keyword">del</span>(dataIndex[randIndex])</span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line"><span class="comment">#应用实例：从疝气病症预测病马的死亡率</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">缺失值处理：</span></span><br><span class="line"><span class="string">    1、使用可用特征的均值来填补缺失值；</span></span><br><span class="line"><span class="string">    2、使用特殊值来填补缺失值，如-1；</span></span><br><span class="line"><span class="string">    3、忽略有缺失值的样本；</span></span><br><span class="line"><span class="string">    4、使用相似样本的均值填补缺失值；</span></span><br><span class="line"><span class="string">    5、使用另外的机器学习算法预测缺失值。</span></span><br><span class="line"><span class="string">    6、标签如果缺失，很难采取某个合适的值进行替换，建议直接删除该样本</span></span><br><span class="line"><span class="string">    我们选用0来替换所有的缺失值，更新的时候不会影响系数的值；该数据集中特征取值一般不为0，所以也满足了特殊值的要求</span></span><br><span class="line"><span class="string">    类别标签：仍存活、已经死亡、已经安乐死，将后两种合并成未能存活，改成一个二分类问题</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyVector</span><span class="params">(inX,weight)</span>:</span></span><br><span class="line">    prob=sigmoid(sum(inX*weight))</span><br><span class="line">    <span class="keyword">if</span> prob&gt;<span class="number">0.5</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">colicTest</span><span class="params">()</span>:</span></span><br><span class="line">    frTrain=open(<span class="string">r'C:\Users\ligua\Videos\我的资源\机器学习实战\machinelearninginaction\Ch05\horseColicTraining.txt'</span>)</span><br><span class="line">    frTest=open(<span class="string">r'C:\Users\ligua\Videos\我的资源\机器学习实战\machinelearninginaction\Ch05\horseColicTest.txt'</span>)</span><br><span class="line">    trainingSet,trainingLabels=[],[]</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTrain.readlines():</span><br><span class="line">        currLine=line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        lineArr=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        trainingSet.append(lineArr)</span><br><span class="line">        trainingLabels.append(float(currLine[<span class="number">21</span>]))</span><br><span class="line">    trainWeights=stocGradAscent1(np.array(trainingSet),trainingLabels,<span class="number">500</span>)</span><br><span class="line">    errorCount,numTestVec=<span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTest.readlines():</span><br><span class="line">        numTestVec+=<span class="number">1.0</span></span><br><span class="line">        currLine=line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        lineArr=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        <span class="keyword">if</span> int(classifyVector(np.array(lineArr),trainWeights))!=int(currLine[<span class="number">21</span>]):</span><br><span class="line">            errorCount+=<span class="number">1</span></span><br><span class="line">    frTrain.close()</span><br><span class="line">    frTest.close()</span><br><span class="line">    errorRate=errorCount/numTestVec</span><br><span class="line">    print(<span class="string">'the error rate of this test is:%f'</span>%(errorRate))</span><br><span class="line">    <span class="keyword">return</span> errorRate</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mulitTest</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    计算十次结果取平均值</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    numTests,errorSum=<span class="number">10</span>,<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(numTests):</span><br><span class="line">        errorSum+=colicTest()</span><br><span class="line">    print(<span class="string">'after %d iterations the average error rate is:%f'</span>%(numTests,errorSum/float(numTests)))</span><br></pre></td></tr></table></figure>
<h6 id="模块调用"><a href="#模块调用" class="headerlink" title="模块调用"></a>模块调用</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logRegres</span><br><span class="line">dataArr,labelMat=logRegres.loadDataSet()</span><br><span class="line">logRegres.gradAscent(dataArr,labelMat)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> imp</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">imp.reload(logRegres)</span><br><span class="line">dataArr,labelMat=logRegres.loadDataSet()</span><br><span class="line">logRegres.stocGradAscent0(np.array(dataArr),labelMat)</span><br><span class="line"></span><br><span class="line">imp.reload(logRegres)</span><br><span class="line">dataArr,labelMat=logRegres.loadDataSet()</span><br><span class="line">logRegres.stocGradAscent1(np.array(dataArr),labelMat)</span><br><span class="line"></span><br><span class="line">imp.reload(logRegres)</span><br><span class="line">logRegres.mulitTest()</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://17091557073.github.io/2019/05/10/o2o-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gavin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/psb.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="L/G's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/10/o2o-1/" itemprop="url">O2O优惠券使用预测</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-10T16:19:00+08:00">
                2019-05-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/天池/" itemprop="url" rel="index">
                    <span itemprop="name">天池</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>赛题链接：</strong></p>
<p><a href="https://tianchi.aliyun.com/getStart/introduction.htm?spm=5176.100066.0.0.518433afBqXIKM&amp;raceId=231593" target="_blank" rel="noopener">天池o2o优惠券使用预测</a></p>
<h2 id="导入相关库"><a href="#导入相关库" class="headerlink" title="导入相关库"></a>导入相关库</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import libraries necessary for this project</span></span><br><span class="line"><span class="keyword">import</span> os, sys, pickle</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> date</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier, LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> log_loss, roc_auc_score, auc, roc_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"> </span><br><span class="line"><span class="comment"># display for this notebook</span></span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'retina'</span></span><br></pre></td></tr></table></figure>
<h2 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dfoff = pd.read_csv(<span class="string">'data/ccf_offline_stage1_train.csv'</span>)</span><br><span class="line">dfon = pd.read_csv(<span class="string">'data/ccf_online_stage1_train.csv'</span>)</span><br><span class="line">dftest = pd.read_csv(<span class="string">'data/ccf_offline_stage1_test_revised.csv'</span>)</span><br><span class="line"> </span><br><span class="line">dfoff.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<h3 id="简单统计"><a href="#简单统计" class="headerlink" title="简单统计"></a>简单统计</h3><p>简单统计一下用户使用优惠券的情况：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'有优惠卷，购买商品：%d'</span> % dfoff[(dfoff[<span class="string">'Date_received'</span>] != <span class="string">'null'</span>) &amp; (dfoff[<span class="string">'Date'</span>] != <span class="string">'null'</span>)].shape[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">'有优惠卷，未购商品：%d'</span> % dfoff[(dfoff[<span class="string">'Date_received'</span>] != <span class="string">'null'</span>) &amp; (dfoff[<span class="string">'Date'</span>] == <span class="string">'null'</span>)].shape[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">'无优惠卷，购买商品：%d'</span> % dfoff[(dfoff[<span class="string">'Date_received'</span>] == <span class="string">'null'</span>) &amp; (dfoff[<span class="string">'Date'</span>] != <span class="string">'null'</span>)].shape[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">'无优惠卷，未购商品：%d'</span> % dfoff[(dfoff[<span class="string">'Date_received'</span>] == <span class="string">'null'</span>) &amp; (dfoff[<span class="string">'Date'</span>] == <span class="string">'null'</span>)].shape[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>有优惠卷，购买商品：75382
有优惠卷，未购商品：977900
无优惠卷，购买商品：701602
无优惠卷，未购商品：0
</code></pre><p>可见，很多人（701602）购买商品却没有使用优惠券，也有很多人（977900）有优惠券但却没有使用，真正使用优惠券购买商品的人（75382）很少！所以，这个比赛的意义就是把优惠券送给真正可能会购买商品的人。</p>
<h2 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfoff.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<h3 id="打折率-Discount-rate"><a href="#打折率-Discount-rate" class="headerlink" title="打折率 Discount_rate"></a>打折率 Discount_rate</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Discount_rate 类型：\n'</span>,dfoff[<span class="string">'Discount_rate'</span>].unique())</span><br></pre></td></tr></table></figure>
<pre><code>Discount_rate 类型：
 [&#39;null&#39; &#39;150:20&#39; &#39;20:1&#39; &#39;200:20&#39; &#39;30:5&#39; &#39;50:10&#39; &#39;10:5&#39; &#39;100:10&#39; &#39;200:30&#39;
 &#39;20:5&#39; &#39;30:10&#39; &#39;50:5&#39; &#39;150:10&#39; &#39;100:30&#39; &#39;200:50&#39; &#39;100:50&#39; &#39;300:30&#39; &#39;50:20&#39;
 &#39;0.9&#39; &#39;10:1&#39; &#39;30:1&#39; &#39;0.95&#39; &#39;100:5&#39; &#39;5:1&#39; &#39;100:20&#39; &#39;0.8&#39; &#39;50:1&#39; &#39;200:10&#39;
 &#39;300:20&#39; &#39;100:1&#39; &#39;150:30&#39; &#39;300:50&#39; &#39;20:10&#39; &#39;0.85&#39; &#39;0.6&#39; &#39;150:50&#39; &#39;0.75&#39;
 &#39;0.5&#39; &#39;200:5&#39; &#39;0.7&#39; &#39;30:20&#39; &#39;300:10&#39; &#39;0.2&#39; &#39;50:30&#39; &#39;200:100&#39; &#39;150:5&#39;]
</code></pre><p>打折率分为 3 种情况：</p>
<ul>
<li><p>‘null’ 表示没有打折</p>
</li>
<li><p>[0,1] 表示折扣率</p>
</li>
<li><p>x:y 表示满x减y</p>
</li>
</ul>
<p><strong>处理方式：</strong></p>
<ul>
<li><p>打折类型：getDiscountType()</p>
</li>
<li><p>折扣率：convertRate()</p>
</li>
<li><p>满多少：getDiscountMan()</p>
</li>
<li><p>减多少：getDiscountJian()</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convert Discount_rate and Distance</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getDiscountType</span><span class="params">(row)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> row == <span class="string">'null'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'null'</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">':'</span> <span class="keyword">in</span> row:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convertRate</span><span class="params">(row)</span>:</span></span><br><span class="line">    <span class="string">"""Convert discount to rate"""</span></span><br><span class="line">    <span class="keyword">if</span> row == <span class="string">'null'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">':'</span> <span class="keyword">in</span> row:</span><br><span class="line">        rows = row.split(<span class="string">':'</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.0</span> - float(rows[<span class="number">1</span>])/float(rows[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> float(row)</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getDiscountMan</span><span class="params">(row)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">':'</span> <span class="keyword">in</span> row:</span><br><span class="line">        rows = row.split(<span class="string">':'</span>)</span><br><span class="line">        <span class="keyword">return</span> int(rows[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getDiscountJian</span><span class="params">(row)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">':'</span> <span class="keyword">in</span> row:</span><br><span class="line">        rows = row.split(<span class="string">':'</span>)</span><br><span class="line">        <span class="keyword">return</span> int(rows[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">processData</span><span class="params">(df)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># convert discount_rate</span></span><br><span class="line">    df[<span class="string">'discount_type'</span>] = df[<span class="string">'Discount_rate'</span>].apply(getDiscountType)</span><br><span class="line">    df[<span class="string">'discount_rate'</span>] = df[<span class="string">'Discount_rate'</span>].apply(convertRate)</span><br><span class="line">    df[<span class="string">'discount_man'</span>] = df[<span class="string">'Discount_rate'</span>].apply(getDiscountMan)</span><br><span class="line">    df[<span class="string">'discount_jian'</span>] = df[<span class="string">'Discount_rate'</span>].apply(getDiscountJian)</span><br><span class="line">    </span><br><span class="line">    print(df[<span class="string">'discount_rate'</span>].unique())</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dfoff = processData(dfoff)</span><br><span class="line">dftest = processData(dftest)</span><br></pre></td></tr></table></figure>
<pre><code>[ 1.          0.86666667  0.95        0.9         0.83333333  0.8         0.5
  0.85        0.75        0.66666667  0.93333333  0.7         0.6
  0.96666667  0.98        0.99        0.975       0.33333333  0.2         0.4       ]
[ 0.83333333  0.9         0.96666667  0.8         0.95        0.75        0.98
  0.5         0.86666667  0.6         0.66666667  0.7         0.85
  0.33333333  0.94        0.93333333  0.975       0.99      ]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfoff.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<h3 id="距离-Distance"><a href="#距离-Distance" class="headerlink" title="距离 Distance"></a>距离 Distance</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Distance 类型：'</span>,dfoff[<span class="string">'Distance'</span>].unique())</span><br></pre></td></tr></table></figure>
<pre><code>Distance 类型： [&#39;0&#39; &#39;1&#39; &#39;null&#39; &#39;2&#39; &#39;10&#39; &#39;4&#39; &#39;7&#39; &#39;9&#39; &#39;3&#39; &#39;5&#39; &#39;6&#39; &#39;8&#39;]
</code></pre><p>将距离 str 转为 int。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># convert distance</span></span><br><span class="line">dfoff[<span class="string">'distance'</span>] = dfoff[<span class="string">'Distance'</span>].replace(<span class="string">'null'</span>, <span class="number">-1</span>).astype(int)</span><br><span class="line">print(dfoff[<span class="string">'distance'</span>].unique())</span><br><span class="line">dftest[<span class="string">'distance'</span>] = dftest[<span class="string">'Distance'</span>].replace(<span class="string">'null'</span>, <span class="number">-1</span>).astype(int)</span><br><span class="line">print(dftest[<span class="string">'distance'</span>].unique())</span><br></pre></td></tr></table></figure>
<pre><code>[ 0  1 -1  2 10  4  7  9  3  5  6  8]
[ 1 -1  5  2  0 10  3  6  7  4  9  8]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfoff.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<h3 id="领劵日期-Date-received"><a href="#领劵日期-Date-received" class="headerlink" title="领劵日期 Date_received"></a>领劵日期 Date_received</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">date_received = dfoff[<span class="string">'Date_received'</span>].unique()</span><br><span class="line">date_received = sorted(date_received[date_received != <span class="string">'null'</span>])</span><br><span class="line"></span><br><span class="line">date_buy = dfoff[<span class="string">'Date'</span>].unique()</span><br><span class="line">date_buy = sorted(date_buy[date_buy != <span class="string">'null'</span>])</span><br><span class="line"></span><br><span class="line">print(<span class="string">'优惠卷收到日期从'</span>,date_received[<span class="number">0</span>],<span class="string">'到'</span>,date_received[<span class="number">-1</span>])</span><br><span class="line">print(<span class="string">'消费日期从'</span>,date_buy[<span class="number">0</span>],<span class="string">'到'</span>,date_buy[<span class="number">-1</span>])</span><br></pre></td></tr></table></figure>
<pre><code>优惠卷收到日期从 20160101 到 20160615
消费日期从 20160101 到 20160630
</code></pre><p><strong>关于领劵日期的特征：</strong></p>
<ul>
<li><p>weekday : {null, 1, 2, 3, 4, 5, 6, 7}</p>
</li>
<li><p>weekday_type : {1, 0}（周六和周日为1，其他为0）</p>
</li>
<li><p>Weekday_1 : {1, 0, 0, 0, 0, 0, 0}</p>
</li>
<li><p>Weekday_2 : {0, 1, 0, 0, 0, 0, 0}</p>
</li>
<li><p>Weekday_3 : {0, 0, 1, 0, 0, 0, 0}</p>
</li>
<li><p>Weekday_4 : {0, 0, 0, 1, 0, 0, 0}</p>
</li>
<li><p>Weekday_5 : {0, 0, 0, 0, 1, 0, 0}</p>
</li>
<li><p>Weekday_6 : {0, 0, 0, 0, 0, 1, 0}</p>
</li>
<li><p>Weekday_7 : {0, 0, 0, 0, 0, 0, 1}</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getWeekday</span><span class="params">(row)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> row == <span class="string">'null'</span>:</span><br><span class="line">        <span class="keyword">return</span> row</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> date(int(row[<span class="number">0</span>:<span class="number">4</span>]), int(row[<span class="number">4</span>:<span class="number">6</span>]), int(row[<span class="number">6</span>:<span class="number">8</span>])).weekday() + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">dfoff[<span class="string">'weekday'</span>] = dfoff[<span class="string">'Date_received'</span>].astype(str).apply(getWeekday)</span><br><span class="line">dftest[<span class="string">'weekday'</span>] = dftest[<span class="string">'Date_received'</span>].astype(str).apply(getWeekday)</span><br><span class="line"></span><br><span class="line"><span class="comment"># weekday_type :  周六和周日为1，其他为0</span></span><br><span class="line">dfoff[<span class="string">'weekday_type'</span>] = dfoff[<span class="string">'weekday'</span>].apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x <span class="keyword">in</span> [<span class="number">6</span>,<span class="number">7</span>] <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">dftest[<span class="string">'weekday_type'</span>] = dftest[<span class="string">'weekday'</span>].apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x <span class="keyword">in</span> [<span class="number">6</span>,<span class="number">7</span>] <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># change weekday to one-hot encoding </span></span><br><span class="line">weekdaycols = [<span class="string">'weekday_'</span> + str(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">8</span>)]</span><br><span class="line"><span class="comment">#print(weekdaycols)</span></span><br><span class="line"></span><br><span class="line">tmpdf = pd.get_dummies(dfoff[<span class="string">'weekday'</span>].replace(<span class="string">'null'</span>, np.nan))</span><br><span class="line">tmpdf.columns = weekdaycols</span><br><span class="line">dfoff[weekdaycols] = tmpdf</span><br><span class="line"></span><br><span class="line">tmpdf = pd.get_dummies(dftest[<span class="string">'weekday'</span>].replace(<span class="string">'null'</span>, np.nan))</span><br><span class="line">tmpdf.columns = weekdaycols</span><br><span class="line">dftest[weekdaycols] = tmpdf</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfoff.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<h3 id="所有特征："><a href="#所有特征：" class="headerlink" title="所有特征："></a>所有特征：</h3><ul>
<li><p>discount_rate</p>
</li>
<li><p>discount_type</p>
</li>
<li><p>discount_man</p>
</li>
<li><p>discount_jian</p>
</li>
<li><p>distance</p>
</li>
<li><p>weekday</p>
</li>
<li><p>weekday_type</p>
</li>
<li><p>weekday_1</p>
</li>
<li><p>weekday_2</p>
</li>
<li><p>weekday_3</p>
</li>
<li><p>weekday_4</p>
</li>
<li><p>weekday_5</p>
</li>
<li><p>weekday_6</p>
</li>
<li><p>weekday_7</p>
</li>
</ul>
<h2 id="标签标注"><a href="#标签标注" class="headerlink" title="标签标注"></a>标签标注</h2><p>三种情况：</p>
<ul>
<li><p>Date_received == ‘null’：表示没有领到优惠券，无需考虑，y = -1</p>
</li>
<li><p>(Date_received != ‘null’) &amp; (Date != ‘null’) &amp; (Date - Date_received &lt;= 15)：表示领取优惠券且在15天内使用，即正样本，y = 1</p>
</li>
<li><p>(Date_received != ‘null’) &amp; ((Date == ‘null’) | (Date - Date_received &gt; 15))：表示领取优惠券未在在15天内使用，即负样本，y = 0</p>
</li>
</ul>
<p>定义标签备注函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">label</span><span class="params">(row)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> row[<span class="string">'Date_received'</span>] == <span class="string">'null'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">    <span class="keyword">if</span> row[<span class="string">'Date'</span>] != <span class="string">'null'</span>:</span><br><span class="line">        td = pd.to_datetime(row[<span class="string">'Date'</span>], format=<span class="string">'%Y%m%d'</span>) - pd.to_datetime(row[<span class="string">'Date_received'</span>], format=<span class="string">'%Y%m%d'</span>)</span><br><span class="line">        <span class="keyword">if</span> td &lt;= pd.Timedelta(<span class="number">15</span>, <span class="string">'D'</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">dfoff[<span class="string">'label'</span>] = dfoff.apply(label, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(dfoff[<span class="string">'label'</span>].value_counts())</span><br></pre></td></tr></table></figure>
<pre><code> 0    988887
-1    701602
 1     64395
Name: label, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfoff.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<h2 id="建立线性模型-SGDClassifier"><a href="#建立线性模型-SGDClassifier" class="headerlink" title="建立线性模型 SGDClassifier"></a>建立线性模型 SGDClassifier</h2><ul>
<li><p>使用上面提取的14个特征。</p>
</li>
<li><p>训练集：20160101-20160515；验证集：20160516-20160615。</p>
</li>
<li><p>用线性模型 SGDClassifier</p>
</li>
</ul>
<h3 id="划分训练集-验证集"><a href="#划分训练集-验证集" class="headerlink" title="划分训练集/验证集"></a>划分训练集/验证集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># data split</span></span><br><span class="line">df = dfoff[dfoff[<span class="string">'label'</span>] != <span class="number">-1</span>].copy()</span><br><span class="line">train = df[(df[<span class="string">'Date_received'</span>] &lt; <span class="string">'20160516'</span>)].copy()</span><br><span class="line">valid = df[(df[<span class="string">'Date_received'</span>] &gt;= <span class="string">'20160516'</span>) &amp; (df[<span class="string">'Date_received'</span>] &lt;= <span class="string">'20160615'</span>)].copy()</span><br><span class="line">print(<span class="string">'Train Set: \n'</span>, train[<span class="string">'label'</span>].value_counts())</span><br><span class="line">print(<span class="string">'Valid Set: \n'</span>, valid[<span class="string">'label'</span>].value_counts())</span><br></pre></td></tr></table></figure>
<pre><code>Train Set: 
 0    759172
1     41524
Name: label, dtype: int64
Valid Set: 
 0    229715
1     22871
Name: label, dtype: int64
</code></pre><h3 id="特征数量"><a href="#特征数量" class="headerlink" title="特征数量"></a>特征数量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># feature</span></span><br><span class="line">original_feature = [<span class="string">'discount_rate'</span>,<span class="string">'discount_type'</span>,<span class="string">'discount_man'</span>, <span class="string">'discount_jian'</span>,<span class="string">'distance'</span>, <span class="string">'weekday'</span>, <span class="string">'weekday_type'</span>] + weekdaycols</span><br><span class="line">print(<span class="string">'共有特征：'</span>,len(original_feature),<span class="string">'个'</span>)</span><br><span class="line">print(original_feature)</span><br></pre></td></tr></table></figure>
<pre><code>共有特征： 14 个
[&#39;discount_rate&#39;, &#39;discount_type&#39;, &#39;discount_man&#39;, &#39;discount_jian&#39;, &#39;distance&#39;, &#39;weekday&#39;, &#39;weekday_type&#39;, &#39;weekday_1&#39;, &#39;weekday_2&#39;, &#39;weekday_3&#39;, &#39;weekday_4&#39;, &#39;weekday_5&#39;, &#39;weekday_6&#39;, &#39;weekday_7&#39;]
</code></pre><h3 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_model</span><span class="params">(data, predictors)</span>:</span></span><br><span class="line">    </span><br><span class="line">    classifier = <span class="keyword">lambda</span>: SGDClassifier(</span><br><span class="line">        loss=<span class="string">'log'</span>,  <span class="comment"># loss function: logistic regression</span></span><br><span class="line">        penalty=<span class="string">'elasticnet'</span>, <span class="comment"># L1 &amp; L2</span></span><br><span class="line">        fit_intercept=<span class="literal">True</span>,  <span class="comment"># 是否存在截距，默认存在</span></span><br><span class="line">        max_iter=<span class="number">100</span>, </span><br><span class="line">        shuffle=<span class="literal">True</span>,  <span class="comment"># Whether or not the training data should be shuffled after each epoch</span></span><br><span class="line">        n_jobs=<span class="number">1</span>, <span class="comment"># The number of processors to use</span></span><br><span class="line">        class_weight=<span class="literal">None</span>) <span class="comment"># Weights associated with classes. If not given, all classes are supposed to have weight one.</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 管道机制使得参数集在新数据集（比如测试集）上的重复使用，管道机制实现了对全部步骤的流式化封装和管理。</span></span><br><span class="line">    model = Pipeline(steps=[</span><br><span class="line">        (<span class="string">'ss'</span>, StandardScaler()), <span class="comment"># transformer</span></span><br><span class="line">        (<span class="string">'en'</span>, classifier())  <span class="comment"># estimator</span></span><br><span class="line">    ])</span><br><span class="line"> </span><br><span class="line">    parameters = &#123;</span><br><span class="line">        <span class="string">'en__alpha'</span>: [ <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>],</span><br><span class="line">        <span class="string">'en__l1_ratio'</span>: [ <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>]</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># StratifiedKFold用法类似Kfold，但是他是分层采样，确保训练集，测试集中各类别样本的比例与原始数据集中相同。</span></span><br><span class="line">    folder = StratifiedKFold(n_splits=<span class="number">3</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Exhaustive search over specified parameter values for an estimator.</span></span><br><span class="line">    grid_search = GridSearchCV(</span><br><span class="line">        model, </span><br><span class="line">        parameters, </span><br><span class="line">        cv=folder, </span><br><span class="line">        n_jobs=<span class="number">-1</span>,  <span class="comment"># -1 means using all processors</span></span><br><span class="line">        verbose=<span class="number">1</span>)</span><br><span class="line">    grid_search = grid_search.fit(data[predictors], </span><br><span class="line">                                  data[<span class="string">'label'</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> grid_search</span><br></pre></td></tr></table></figure>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predictors = original_feature</span><br><span class="line">model = check_model(train, predictors)</span><br></pre></td></tr></table></figure>
<pre><code>Fitting 3 folds for each of 9 candidates, totalling 27 fits


[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  3.0min finished
</code></pre><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>对验证集中每个优惠券预测的结果计算 AUC，再对所有优惠券的 AUC 求平均。计算 AUC 的时候，如果 label 只有一类，就直接跳过，因为 AUC 无法计算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># valid predict</span></span><br><span class="line">y_valid_pred = model.predict_proba(valid[predictors])</span><br><span class="line">valid1 = valid.copy()</span><br><span class="line">valid1[<span class="string">'pred_prob'</span>] = y_valid_pred[:, <span class="number">1</span>]</span><br><span class="line">valid1.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>计算 AUC：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># avgAUC calculation</span></span><br><span class="line">vg = valid1.groupby([<span class="string">'Coupon_id'</span>])</span><br><span class="line">aucs = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> vg:</span><br><span class="line">    tmpdf = i[<span class="number">1</span>] </span><br><span class="line">    <span class="keyword">if</span> len(tmpdf[<span class="string">'label'</span>].unique()) != <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    fpr, tpr, thresholds = roc_curve(tmpdf[<span class="string">'label'</span>], tmpdf[<span class="string">'pred_prob'</span>], pos_label=<span class="number">1</span>)</span><br><span class="line">    aucs.append(auc(fpr, tpr))</span><br><span class="line">print(np.average(aucs))</span><br></pre></td></tr></table></figure>
<pre><code>0.532344469452
</code></pre><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test prediction for submission</span></span><br><span class="line">y_test_pred = model.predict_proba(dftest[predictors])</span><br><span class="line">dftest1 = dftest[[<span class="string">'User_id'</span>,<span class="string">'Coupon_id'</span>,<span class="string">'Date_received'</span>]].copy()</span><br><span class="line">dftest1[<span class="string">'Probability'</span>] = y_test_pred[:,<span class="number">1</span>]</span><br><span class="line">dftest1.to_csv(<span class="string">'submit1.csv'</span>, index=<span class="literal">False</span>, header=<span class="literal">False</span>)</span><br><span class="line">dftest1.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<h3 id="保存模型-amp-导入模型"><a href="#保存模型-amp-导入模型" class="headerlink" title="保存模型 &amp; 导入模型"></a>保存模型 &amp; 导入模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isfile(<span class="string">'1_model.pkl'</span>):</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'1_model.pkl'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        pickle.dump(model, f)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'1_model.pkl'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        model = pickle.load(f)</span><br></pre></td></tr></table></figure>
<h3 id="改用决策数算法训练模型"><a href="#改用决策数算法训练模型" class="headerlink" title="改用决策数算法训练模型"></a>改用决策数算法训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_model</span><span class="params">(data, predictors)</span>:</span>    </span><br><span class="line">    classifier = DecisionTreeClassifier(random_state=<span class="number">1</span>)    </span><br><span class="line">    parameters = &#123;</span><br><span class="line">        <span class="string">'max_leaf_nodes'</span>: list(range(<span class="number">2</span>, <span class="number">100</span>)), </span><br><span class="line">        <span class="string">'min_samples_split'</span>: [<span class="number">8</span>, <span class="number">10</span>, <span class="number">15</span>]</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="comment"># StratifiedKFold用法类似Kfold，但是他是分层采样，确保训练集，测试集中各类别样本的比例与原始数据集中相同。</span></span><br><span class="line">    folder = StratifiedKFold(n_splits=<span class="number">3</span>, shuffle=<span class="literal">True</span>)    </span><br><span class="line">    <span class="comment"># Exhaustive search over specified parameter values for an estimator.</span></span><br><span class="line">    grid_search = GridSearchCV(</span><br><span class="line">        classifier, </span><br><span class="line">        parameters, </span><br><span class="line">        cv=folder, </span><br><span class="line">        n_jobs=<span class="number">-1</span>,  <span class="comment"># -1 means using all processors</span></span><br><span class="line">        verbose=<span class="number">1</span>)</span><br><span class="line">    grid_search = grid_search.fit(data[predictors].values,</span><br><span class="line">    data[<span class="string">'label'</span>].values)<span class="comment">#parallel报错加上了.values</span></span><br><span class="line">    <span class="keyword">return</span> grid_search</span><br><span class="line">    </span><br><span class="line">predictors = original_feature</span><br><span class="line">model = check_model(train, predictors)</span><br><span class="line"></span><br><span class="line"><span class="comment"># valid predict</span></span><br><span class="line">y_valid_pred = model.predict_proba(valid[predictors])</span><br><span class="line">valid1 = valid.copy()</span><br><span class="line">valid1[<span class="string">'pred_prob'</span>] = y_valid_pred[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># avgAUC calculation</span></span><br><span class="line">vg = valid1.groupby([<span class="string">'Coupon_id'</span>])</span><br><span class="line">aucs = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> vg:</span><br><span class="line">    tmpdf = i[<span class="number">1</span>] </span><br><span class="line">    <span class="keyword">if</span> len(tmpdf[<span class="string">'label'</span>].unique()) != <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    fpr, tpr, thresholds = roc_curve(tmpdf[<span class="string">'label'</span>], tmpdf[<span class="string">'pred_prob'</span>], pos_label=<span class="number">1</span>)</span><br><span class="line">    aucs.append(auc(fpr, tpr))</span><br><span class="line">print(np.average(aucs))</span><br><span class="line"></span><br><span class="line"><span class="comment"># test prediction for submission</span></span><br><span class="line">y_test_pred = model.predict_proba(dftest[predictors])</span><br><span class="line">dftest1 = dftest[[<span class="string">'User_id'</span>,<span class="string">'Coupon_id'</span>,<span class="string">'Date_received'</span>]].copy()</span><br><span class="line">dftest1[<span class="string">'Probability'</span>] = y_test_pred[:,<span class="number">1</span>]</span><br><span class="line">dftest1.to_csv(<span class="string">'submit1-dt.csv'</span>, index=<span class="literal">False</span>, header=<span class="literal">False</span>)</span><br><span class="line">dftest1.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<h2 id="优化模型…"><a href="#优化模型…" class="headerlink" title="优化模型…"></a>优化模型…</h2><ul>
<li><p><strong>特征工程</strong></p>
</li>
<li><p><strong>机器学习算法</strong></p>
</li>
<li><p><strong>模型集成</strong></p>
</li>
</ul>
<h2 id="参考代码"><a href="#参考代码" class="headerlink" title="参考代码"></a>参考代码</h2><p><a href="https://github.com/wepe/O2O-Coupon-Usage-Forecast" target="_blank" rel="noopener">比赛第一名代码与解析</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://17091557073.github.io/2019/05/08/朴素贝叶斯算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gavin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/psb.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="L/G's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/08/朴素贝叶斯算法/" itemprop="url">朴素贝叶斯算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-08T16:49:00+08:00">
                2019-05-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习实战/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习实战</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li>条件概率<br>p(c|x)=p(x|c)*p(c)/p(x)<br><a href="https://mp.weixin.qq.com/s/7xRyZJpXmeB77MZNLqVf3w" target="_blank" rel="noopener">联合概率和全概率公式</a></li>
<li>朴素贝叶斯<br>朴素：假设每个特征之间<strong>相互独立</strong>且<strong>同等重要</strong>；条件概率公式中的联合概率p(x0,x1…xN|c)等价于p(x0|c)<em>p(x1|c)</em>…p(xN|c),极大地简化了计算过程；主要有<a href="https://blog.csdn.net/lming_08/article/details/37542331" target="_blank" rel="noopener">两种实现方式</a>：<ul>
<li><strong>贝努利模型（词集模型）：</strong>考虑词在文档中出现与否（相当于特征是等权重的）；P(c)= 类c下文件总数/整个训练样本的文档总数<br>P(tk|c)=(类c下包括单词tk的文件数+1)/(类c下文档总数+2) ；  在这里，m=2, p=1/2。  这里一定要注意：伯努利是以文档为粒度的，所以分母是文档总数，而不是网上以讹传讹的类c下单词总数</li>
<li><strong>多项式模型（词袋模型）：</strong>考虑词在文档中出现的次数<br>在多项式模型中。 设某文档d=(t1,t2,…,tk)。tk是该文档中出现过的单词。同意反复。则<br>先验概率P(c)= 类c下单词总数/整个训练样本的单词总数<br>类条件概率P(tk|c)=(类c下单词tk在各个文档中出现过的次数之和+1)/(类c下单词总数+|V|)<br>V是训练样本的单词表（即抽取单词集合。单词出现多次，仅仅算一个），|V|则表示训练样本包括多少种单词。在这里，m=|V|, p=1/|V|。<br>P(tk|c)能够看作是单词tk在证明d属于类c上提供了多大的证据。而P(c)则能够觉得是类别c在总体上占多大比例(有多大可能性)。</li>
</ul>
</li>
<li>文档分类<br>先分词，把每个词出现或不出现作为一个特征；特征数量较大，故采用直方图来分析数据效果较好；要得到好的概率分布，需要足够的数据样本，特征数越多，所需样本量越大（假设每个特征需要N个样本，10个特征则需要N^10数据量，如果相互独立，数量可降至N*10）；最后计算每个独立特征的条件概率;<br>在文档分类问题中，词袋模型比词集模型效果更好些；除此之外，还可以通过移除高频词、停用词，优化单词切分器来提高准确率。</li>
</ol>
<hr>
<h6 id="python代码实现"><a href="#python代码实现" class="headerlink" title="python代码实现"></a>python代码实现</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Thu May  9 14:14:53 2019</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: LiGuan</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@desc: 朴素贝叶斯算法</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    生成训练数据#文档数据来自斑点狗爱好者留言板</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    postingList=[[<span class="string">'my'</span>,<span class="string">'dog'</span>,<span class="string">'has'</span>,<span class="string">'flea'</span>,<span class="string">'problem'</span>,<span class="string">'help'</span>,<span class="string">'please'</span>],</span><br><span class="line">                 [<span class="string">'maybe'</span>,<span class="string">'not'</span>,<span class="string">'take'</span>,<span class="string">'him'</span>,<span class="string">'to'</span>,<span class="string">'dog'</span>,<span class="string">'park'</span>,<span class="string">'stupid'</span>],</span><br><span class="line">                 [<span class="string">'my'</span>,<span class="string">'dalmations'</span>,<span class="string">'is'</span>,<span class="string">'so'</span>,<span class="string">'cute'</span>,<span class="string">'I'</span>,<span class="string">'love'</span>,<span class="string">'him'</span>],</span><br><span class="line">                 [<span class="string">'stop'</span>,<span class="string">'posting'</span>,<span class="string">'stupid'</span>,<span class="string">'worthless'</span>,<span class="string">'garbage'</span>],</span><br><span class="line">                 [<span class="string">'mr'</span>,<span class="string">'licks'</span>,<span class="string">'ate'</span>,<span class="string">'my'</span>,<span class="string">'steak'</span>,<span class="string">'how'</span>,<span class="string">'to'</span>,<span class="string">'stop'</span>,<span class="string">'him'</span>],</span><br><span class="line">                 [<span class="string">'quit'</span>,<span class="string">'buying'</span>,<span class="string">'worthless'</span>,<span class="string">'dog'</span>,<span class="string">'food'</span>,<span class="string">'stupid'</span>]]<span class="comment">#(),[],&#123;&#125;中的换行不用加 \</span></span><br><span class="line">    classVec=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>]<span class="comment">#1代表侮辱性文字，0代表正常言论；文本类别由人工标注</span></span><br><span class="line">    <span class="keyword">return</span> postingList,classVec</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    创建一个文档中不重复词的列表</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    vocabSet=set([])<span class="comment">#创建一个空集</span></span><br><span class="line">    <span class="keyword">for</span> documnet <span class="keyword">in</span> dataSet:</span><br><span class="line">        vocabSet=vocabSet | set(documnet)<span class="comment">#创建两个集合的并集</span></span><br><span class="line">    <span class="keyword">return</span> list(vocabSet)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setOfWords2Vec</span><span class="params">(vocabList,inputSet)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    将一篇分词后文档转为词向量</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    returnVec=[<span class="number">0</span>]*len(vocabList)<span class="comment">#创建一个元素都为0的向量</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</span><br><span class="line">            returnVec[vocabList.index(word)]=<span class="number">1</span><span class="comment">#词汇表中的单词在输入文档中出现与否（0|1）</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">'the word: %s is not in my Vocabulary!'</span>% word)</span><br><span class="line">    <span class="keyword">return</span> returnVec</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNB0</span><span class="params">(trainMatrix,trainCategory)</span>:</span></span><br><span class="line">    numTrainDocs=len(trainMatrix)</span><br><span class="line">    numWords=len(trainMatrix[<span class="number">0</span>])</span><br><span class="line">    pAbusive=sum(trainCategory)/numTrainDocs</span><br><span class="line">    p0Num,p1Num=np.ones(numWords),np.ones(numWords)</span><br><span class="line">    <span class="comment">#拉普拉斯平滑，解决零概率的问题</span></span><br><span class="line">    p0Denom,p1Denom=<span class="number">2</span>,<span class="number">2</span><span class="comment">#将初始化分子由0改成1，分母由0改成2，为了防止其中某一项为0时整个值变成0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTrainDocs):</span><br><span class="line">        <span class="keyword">if</span> trainCategory[i]==<span class="number">1</span>:</span><br><span class="line">            p1Num+=trainMatrix[i]</span><br><span class="line">            p1Denom+=<span class="number">1</span></span><br><span class="line">            <span class="comment">#p1Denom+=sum(trainMatrix[i])</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            p0Num+=trainMatrix[i]</span><br><span class="line">            p0Denom+=<span class="number">1</span></span><br><span class="line">            <span class="comment">#p0Denom+=sum(trainMatrix[i])</span></span><br><span class="line">    p1Vect=np.log(p1Num/p1Denom)</span><br><span class="line">    p0Vect=np.log(p0Num/p0Denom)<span class="comment">#改成取对数是为了避免数值下溢出（大部分因子都特别小，导致总乘积接近0）</span></span><br><span class="line">    <span class="keyword">return</span> p0Vect,p1Vect,pAbusive</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyNB</span><span class="params">(vec2Classify,p0Vec,p1Vec,pClass1)</span>:</span></span><br><span class="line">    <span class="comment">#对应元素相乘。logA * B = logA + logB</span></span><br><span class="line">    p1=np.sum(vec2Classify*p1Vec)+np.log(pClass1)</span><br><span class="line">    p0=np.sum(vec2Classify*p0Vec)+np.log(<span class="number">1.0</span>-pClass1)</span><br><span class="line">    <span class="keyword">if</span> p1&gt;p0:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testingNB</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    封装了生成数据，调用算法的所有操作</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    listOPosts,listClasses=loadDataSet()</span><br><span class="line">    myVocabList=createVocabList(listOPosts)</span><br><span class="line">    trainMat=[]</span><br><span class="line">    <span class="keyword">for</span> postinDoc <span class="keyword">in</span> listOPosts:</span><br><span class="line">        trainMat.append(setOfWords2Vec(myVocabList,postinDoc))</span><br><span class="line">    p0V,p1V,pAb=trainNB0(np.array(trainMat),np.array(listClasses))</span><br><span class="line">    testEntry=[<span class="string">'love'</span>,<span class="string">'my'</span>,<span class="string">'dalmation'</span>]</span><br><span class="line">    thisDoc=np.array(setOfWords2Vec(myVocabList,testEntry))</span><br><span class="line">    print(testEntry,<span class="string">'classified as:&#123;&#125;'</span>.format(classifyNB(thisDoc,p0V,p1V,pAb)))</span><br><span class="line">    testEntry=[<span class="string">'stupid'</span>,<span class="string">'garbage'</span>]</span><br><span class="line">    thisDoc=np.array(setOfWords2Vec(myVocabList,testEntry))</span><br><span class="line">    print(testEntry,<span class="string">'classified as:&#123;&#125;'</span>.format(classifyNB(thisDoc,p0V,p1V,pAb)))</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bagOfWords2VecMN</span><span class="params">(vocabList,inputSet)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    词袋模型，单词每遇到一次就加一，区别于词集模型</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    returnVec=[<span class="number">0</span>]*len(vocabList)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</span><br><span class="line">            returnVec[vocabList.index(word)]+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> returnVec</span><br><span class="line"><span class="comment">#使用朴素贝叶斯进行交叉验证   </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">textParse</span><span class="params">(bigString)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> re</span><br><span class="line">    listOfTokens=re.split(<span class="string">r'\W+'</span>,bigString)</span><br><span class="line">    <span class="keyword">return</span> [tok.lower() <span class="keyword">for</span> tok <span class="keyword">in</span> listOfTokens <span class="keyword">if</span> len(tok)&gt;<span class="number">2</span>]</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spamTest</span><span class="params">()</span>:</span></span><br><span class="line">    docList,classList,fullText=[],[],[]</span><br><span class="line">    <span class="comment">#导入并解析好坏邮件</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">26</span>):</span><br><span class="line">        wordList=textParse(open(<span class="string">r'C:\Users\ligua\Videos\我的资源\机器学习实战\machinelearninginaction\Ch04\email\spam\%d.txt'</span>%i,encoding=<span class="string">"ISO-8859-1"</span>).read())</span><br><span class="line">        docList.append(wordList)</span><br><span class="line">        fullText.extend(wordList)</span><br><span class="line">        classList.append(<span class="number">1</span>)</span><br><span class="line">        wordList=textParse(open(<span class="string">r'C:\Users\ligua\Videos\我的资源\机器学习实战\machinelearninginaction\Ch04\email\ham\%d.txt'</span>%i,encoding=<span class="string">"ISO-8859-1"</span>).read())</span><br><span class="line">        docList.append(wordList)</span><br><span class="line">        fullText.extend(wordList)</span><br><span class="line">        classList.append(<span class="number">0</span>)</span><br><span class="line">    vocabList=createVocabList(docList)</span><br><span class="line">    trainingSet=list(range(<span class="number">50</span>));testSet=[]</span><br><span class="line">    <span class="comment">#随机构建训练集</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        randIndex=int(random.uniform(<span class="number">0</span>,len(trainingSet)))</span><br><span class="line">        testSet.append(trainingSet[randIndex])</span><br><span class="line">        <span class="keyword">del</span>(trainingSet[randIndex])</span><br><span class="line">    trainMat,trainClasses=[],[]</span><br><span class="line">    <span class="keyword">for</span> docIndex <span class="keyword">in</span> trainingSet:</span><br><span class="line">        trainMat.append(setOfWords2Vec(vocabList,docList[docIndex]))</span><br><span class="line">        trainClasses.append(classList[docIndex])</span><br><span class="line">    p0V,p1V,pSpam=trainNB0(np.array(trainMat),np.array(trainClasses))</span><br><span class="line">    errorCount=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> docIndex <span class="keyword">in</span> testSet:</span><br><span class="line">        <span class="comment">#对测试集进行分类</span></span><br><span class="line">        wordVector=setOfWords2Vec(vocabList,docList[docIndex])</span><br><span class="line">        <span class="keyword">if</span> classifyNB(np.array(wordVector),p0V,p1V,pSpam)!=classList[docIndex]:</span><br><span class="line">            errorCount+=<span class="number">1</span></span><br><span class="line">            print(<span class="string">"classification error"</span>, docList[docIndex])</span><br><span class="line">    print(<span class="string">'the error rate is:%f'</span>%(float(errorCount)/len(testSet)))</span><br></pre></td></tr></table></figure>
<h5 id="模块调用"><a href="#模块调用" class="headerlink" title="模块调用"></a>模块调用</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Thu May  9 15:21:05 2019</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: LiGuan</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@desc: </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> bayes</span><br><span class="line"><span class="keyword">import</span> imp</span><br><span class="line"></span><br><span class="line">imp.reload(bayes)</span><br><span class="line">listOPosts,listClasses=bayes.loadDataSet()</span><br><span class="line">myVocabList=bayes.createVocabList(listOPosts)</span><br><span class="line">bayes.setOfWords2Vec(myVocabList,listOPosts[<span class="number">0</span>])</span><br><span class="line">bayes.setOfWords2Vec(myVocabList,listOPosts[<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">imp.reload(bayes)</span><br><span class="line">myVocabList=bayes.createVocabList(listOPosts)</span><br><span class="line">trainMat=[]</span><br><span class="line"><span class="keyword">for</span> postinDoc <span class="keyword">in</span> listOPosts:</span><br><span class="line">    trainMat.append(bayes.setOfWords2Vec(myVocabList,postinDoc))</span><br><span class="line">p0V,p1V,pAb=bayes.trainNB0(trainMat,listClasses)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">imp.reload(bayes)</span><br><span class="line">listOPosts,listClasses=bayes.loadDataSet()</span><br><span class="line">myVocabList=bayes.createVocabList(listOPosts)</span><br><span class="line">trainMat=[]</span><br><span class="line"><span class="keyword">for</span> postinDoc <span class="keyword">in</span> listOPosts:</span><br><span class="line">    trainMat.append(bayes.setOfWords2Vec(myVocabList,postinDoc))</span><br><span class="line"><span class="comment">#输出两个类别的概率向量（条件概率），和属于侮辱性文档的概率(先验概率)</span></span><br><span class="line">p0V,p1V,pAb=bayes.trainNB0(trainMat,listClasses)</span><br><span class="line"></span><br><span class="line">imp.reload(bayes)</span><br><span class="line">bayes.testingNB()</span><br><span class="line"></span><br><span class="line">mySent=<span class="string">'This book is the best book on Python or M.L. I have ever laid eyes upon'</span></span><br><span class="line">mySent.split()</span><br><span class="line"><span class="comment">#引入正则表达式，将除单词、数字外的任意字符作为分隔符</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">regEx=re.compile(<span class="string">'\\W*'</span>)</span><br><span class="line">listOfTokens=regEx.split(mySent)</span><br><span class="line">emailText=open(<span class="string">r'C:\Users\ligua\Videos\我的资源\机器学习实战\machinelearninginaction\Ch04\email\ham\6.txt'</span>).read()</span><br><span class="line">listOfTokens=regEx.split(emailText)</span><br><span class="line"></span><br><span class="line">imp.reload(bayes)</span><br><span class="line">bayes.spamTest()<span class="comment">#交叉验证，重复执行该方法10次，求平均错误率</span></span><br></pre></td></tr></table></figure>
<hr>
<h5 id="朴素贝叶斯算法应用"><a href="#朴素贝叶斯算法应用" class="headerlink" title="朴素贝叶斯算法应用"></a>朴素贝叶斯算法应用</h5><p><img src="/2019/05/08/朴素贝叶斯算法/朴素贝叶斯算法应用.jpg" alt="朴素贝叶斯算法应用"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://17091557073.github.io/2019/05/04/决策树/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gavin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/psb.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="L/G's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/04/决策树/" itemprop="url">决策树算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-04T22:38:00+08:00">
                2019-05-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习实战/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习实战</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h6 id="step1"><a href="#step1" class="headerlink" title="step1:"></a>step1:</h6><p>依据哪个属性来划分数据，使无序数据变得更加有序；划分数据集前后信息量发生的变化称为信息增益，计算每个特征属性划分数据集时的信息增益，最高那个特征就是最好的选择</p>
<h6 id="step2"><a href="#step2" class="headerlink" title="step2:"></a>step2:</h6><p>以此递归直至遍历完所有特征属性，或者每个分支下所有实例具有相同的分类（存在某些算法C4.5,CART划分时不消耗特征，以后再讨论），ID3算法只能处理离散性特征</p>
<h6 id="step3"><a href="#step3" class="headerlink" title="step3:"></a>step3:</h6><p>如果已经处理了所有的特征，但类标签还不是唯一的，通常我们会采用多数表决法来确定叶子节点的分类</p>
<hr>
<h6 id="python代码实现"><a href="#python代码实现" class="headerlink" title="python代码实现"></a>python代码实现</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    计算给定数据集的香农熵</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    numEntries=len(dataSet)</span><br><span class="line">    labelCounts=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">        currentLabel=featVec[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys():</span><br><span class="line">            labelCounts[currentLabel]=<span class="number">0</span></span><br><span class="line">        labelCounts[currentLabel]+=<span class="number">1</span></span><br><span class="line">    shannonEnt=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:</span><br><span class="line">        prob=float(labelCounts[key])/numEntries</span><br><span class="line">        shannonEnt-=prob*log(prob,<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> shannonEnt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    dataSet=[[<span class="number">1</span>,<span class="number">1</span>,<span class="string">'yes'</span>],</span><br><span class="line">             [<span class="number">1</span>,<span class="number">1</span>,<span class="string">'yes'</span>],</span><br><span class="line">             [<span class="number">1</span>,<span class="number">0</span>,<span class="string">'no'</span>],</span><br><span class="line">             [<span class="number">0</span>,<span class="number">1</span>,<span class="string">'no'</span>],</span><br><span class="line">             [<span class="number">0</span>,<span class="number">1</span>,<span class="string">'no'</span>]]</span><br><span class="line">    labels=[<span class="string">'no surfacing'</span>,<span class="string">'flippers'</span>]</span><br><span class="line">    <span class="keyword">return</span> dataSet,labels</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet</span><span class="params">(dataSet,axis,value)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">     按照给定特征划分数据集</span></span><br><span class="line"><span class="string">     '''</span></span><br><span class="line">    retDataSet=[]<span class="comment">#函数中传递的是列表的引用，函数中修改会影响整个生存周期,所以在每次调用的时候都新建一个</span></span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">if</span> featVec[axis]==value:</span><br><span class="line">            reducedFeatVec=featVec[:axis]</span><br><span class="line">            reducedFeatVec.extend(featVec[axis+<span class="number">1</span>:])</span><br><span class="line">            retDataSet.append(reducedFeatVec)</span><br><span class="line">    <span class="keyword">return</span> retDataSet</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeatureToSplit</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    选择最好的数据集划分方式（按哪个特征划分信息增益最大）</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    numFeatures=len(dataSet[<span class="number">0</span>])<span class="number">-1</span></span><br><span class="line">    baseEntropy=calcShannonEnt(dataSet)</span><br><span class="line">    bestInfoGain=<span class="number">0.0</span></span><br><span class="line">    bestFeature=<span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):</span><br><span class="line">        featList=[example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">        uniqueVals=set(featList)</span><br><span class="line">        newEntropy=<span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">            subDataSet=splitDataSet(dataSet,i,value)</span><br><span class="line">            prob=len(subDataSet)/float(len(dataSet))</span><br><span class="line">            newEntropy+=prob*calcShannonEnt(subDataSet)</span><br><span class="line">        infoGain=baseEntropy-newEntropy</span><br><span class="line">        <span class="keyword">if</span> infoGain&gt;bestInfoGain:</span><br><span class="line">            bestInfoGain=infoGain</span><br><span class="line">            bestFeature=i</span><br><span class="line">    <span class="keyword">return</span> bestFeature</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">majorityCnt</span><span class="params">(classList)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    多数表决法确定叶子节点分类</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    classCount=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:</span><br><span class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount.keys():</span><br><span class="line">            classCount[vote]=<span class="number">0</span></span><br><span class="line">        classCount[vote]+=<span class="number">1</span></span><br><span class="line">    sortedClassCount=sorted(classCount.items(),key=operator.itemgetter(<span class="number">1</span>),reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet,labels)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    递归函数实现整棵树</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    classList=[example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>])==len(classList):</span><br><span class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]<span class="comment">#类别完全相同则停止继续划分</span></span><br><span class="line">    <span class="keyword">if</span> len(dataSet[<span class="number">0</span>])==<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> majorityCnt(classList)<span class="comment">#遍历完所有特征时返回出现次数最多的</span></span><br><span class="line">    bestFeat=chooseBestFeatureToSplit(dataSet)</span><br><span class="line">    bestFeatLabel=labels[bestFeat]</span><br><span class="line">    myTree=&#123;bestFeatLabel:&#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">del</span>(labels[bestFeat])</span><br><span class="line">    featValues=[example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    uniqueVals=set(featValues)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">        subLabels=labels[:]</span><br><span class="line">        myTree[bestFeatLabel][value]=createTree(splitDataSet(dataSet,bestFeat,value),subLabels)</span><br><span class="line">    <span class="keyword">return</span> myTree</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(inputTree,featLabels,testVec)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    字典决策树的使用</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    firstStr=list(inputTree.keys())[<span class="number">0</span>]</span><br><span class="line">    secondDict=inputTree[firstStr]</span><br><span class="line">    featIndex=featLabels.index(firstStr)</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> secondDict.keys():</span><br><span class="line">        <span class="keyword">if</span> testVec[featIndex]==key:</span><br><span class="line">            <span class="keyword">if</span> type(secondDict[key]).__name__==<span class="string">'dict'</span>:</span><br><span class="line">                classLabel=classify(secondDict[key],featLabels,testVec)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                classLabel=secondDict[key]</span><br><span class="line">    <span class="keyword">return</span> classLabel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="comment">#决策树字典的序列化化和反序列化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">storeTree</span><span class="params">(inputTree,filename)</span>:</span></span><br><span class="line">    fw=open(filename,<span class="string">'w'</span>)</span><br><span class="line">    pickle.dump(inputTree,fw)</span><br><span class="line">    fw.close()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grabTree</span><span class="params">(filename)</span>:</span></span><br><span class="line">    fr=open(filename)</span><br><span class="line">    <span class="keyword">return</span> pickle.load(fr)</span><br></pre></td></tr></table></figure>
<h6 id="模块调用"><a href="#模块调用" class="headerlink" title="模块调用"></a>模块调用</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> trees</span><br><span class="line"></span><br><span class="line">myDat,labels=trees.createDataSet()</span><br><span class="line">trees.calcShannonEnt(myDat)<span class="comment">#0.97095</span></span><br><span class="line"></span><br><span class="line">myDat[<span class="number">0</span>][<span class="number">-1</span>]=<span class="string">'maybe'</span><span class="comment">#添加分类</span></span><br><span class="line">trees.calcShannonEnt(myDat)<span class="comment">#1.37095</span></span><br><span class="line"><span class="comment">#数据越混乱，熵值越高</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> imp</span><br><span class="line">imp.reload(trees)</span><br><span class="line">myDat,labels=trees.createDataSet()</span><br><span class="line">trees.splitDataSet(myDat,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">imp.reload(trees)</span><br><span class="line">trees.chooseBestFeatureToSplit(myDat)</span><br><span class="line"></span><br><span class="line">imp.reload(trees)</span><br><span class="line">myDat,labels=trees.createDataSet()</span><br><span class="line">mytree=trees.createTree(myDat,labels)</span><br><span class="line"><span class="comment">#&#123;'no surfacing': &#123;0: 'no', 1: &#123;'flippers': &#123;0: 'no', 1: 'yes'&#125;&#125;&#125;&#125;</span></span><br><span class="line"></span><br><span class="line">imp.reload(trees)</span><br><span class="line">trees.classify(mytree,labels,[<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">trees.classify(mytree,labels,[<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">imp.reload(trees)</span><br><span class="line">fr=open(<span class="string">'.\machinelearninginaction\Ch03\lenses.txt'</span>)</span><br><span class="line">lenses=[inst.strip().split(<span class="string">'\t'</span>) <span class="keyword">for</span> inst <span class="keyword">in</span> fr.readlines()]<span class="comment">#跟游标类似，只能读取一次</span></span><br><span class="line">lensesLabels=[<span class="string">'age'</span>,<span class="string">'prescript'</span>,<span class="string">'astigmatic'</span>,<span class="string">'tearRate'</span>]</span><br><span class="line">lensesTree=trees.createTree(lenses,lensesLabels)</span><br></pre></td></tr></table></figure>
<hr>
<h6 id="手动计算信息增益"><a href="#手动计算信息增益" class="headerlink" title="手动计算信息增益"></a>手动计算信息增益</h6><p><img src="/2019/05/04/决策树/信息增益.jpg" alt="信息增益计算"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/psb.jpg" alt="Gavin">
            
              <p class="site-author-name" itemprop="name">Gavin</p>
              <p class="site-description motion-element" itemprop="description">AI/机器学习/数据挖掘/python</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="mailto:liguanchn@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Gavin</span>

  
</div>


<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数：<span id="busuanzi_value_site_uv"></span>
</span>
</div>

<!--  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>
-->




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
